{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0968ea6b",
   "metadata": {},
   "source": [
    "# Second part: Miracle in the Andes by Nando Parrado (2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0dff7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"miracle_in_the_andes.txt\", \"r\") as file:\n",
    "    book = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee21a7a7",
   "metadata": {},
   "source": [
    "## The most used words (non-articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9128887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile(\"[a-zA-Z]+\")\n",
    "findings = re.findall(pattern, book.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d910df8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for word in findings:\n",
    "    if word in d.keys():\n",
    "        d[word] = d[word] + 1\n",
    "    else:\n",
    "        d[word] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cae45298",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list = [(value, key) for (key, value) in d.items()]\n",
    "d_list = sorted(d_list, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4a97961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0e7a971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# first time I needed to write in python terminal in this order:\n",
    "# python3.10\n",
    "# install nltk\n",
    "# import nltk\n",
    "# nltk.download(\"stopwords\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "english_stopwords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c742cd",
   "metadata": {},
   "source": [
    " What we've got is a list of articles, pronouns and such very often words in english language that are not that important when analysing contents of the book. We would rather analyse some other type of words which could give us better overview of the contents. Now we want to see which are the most often used words that are NOT in this list english_stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec452ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "240715ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_d = []\n",
    "for count, word in d_list:\n",
    "    if word not in english_stopwords:\n",
    "        filtered_d.append((word, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a67e01d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('would', 575),\n",
       " ('us', 519),\n",
       " ('said', 292),\n",
       " ('roberto', 284),\n",
       " ('could', 252),\n",
       " ('one', 249)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_d[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd6f813",
   "metadata": {},
   "source": [
    "## Sentiment analysis: What is the most positive and the most negative chapter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b59ca281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I needed to write \n",
    "# nltk.download('vader_lexicon') \n",
    "# in a python3.10 terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd2cc4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da672d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a729ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['constants',\n",
       " 'lexicon',\n",
       " 'lexicon_file',\n",
       " 'make_lex_dict',\n",
       " 'polarity_scores',\n",
       " 'score_valence',\n",
       " 'sentiment_valence']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(analyzer)[35:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25b9e592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.431, 'pos': 0.569, 'compound': 0.7417}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.polarity_scores(\"Hey, you look so beautiful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34728ab4",
   "metadata": {},
   "source": [
    "Negative, neutral and positive scores range from 0 to 1, whereas the compound score ranges from -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4eda8e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "pattern = re.compile(\"Chapter [0-9]+\")\n",
    "chapters = re.split(pattern, book)\n",
    "len(chapters)\n",
    "chapters[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65580ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = chapters[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00c61fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1 {'neg': 0.061, 'neu': 0.779, 'pos': 0.16, 'compound': 1.0}\n",
      "Chapter 2 {'neg': 0.12, 'neu': 0.726, 'pos': 0.154, 'compound': 0.9991}\n",
      "Chapter 3 {'neg': 0.145, 'neu': 0.751, 'pos': 0.105, 'compound': -0.9999}\n",
      "Chapter 4 {'neg': 0.141, 'neu': 0.721, 'pos': 0.138, 'compound': -0.9963}\n",
      "Chapter 5 {'neg': 0.118, 'neu': 0.742, 'pos': 0.141, 'compound': 0.9997}\n",
      "Chapter 6 {'neg': 0.124, 'neu': 0.761, 'pos': 0.115, 'compound': -0.9979}\n",
      "Chapter 7 {'neg': 0.136, 'neu': 0.761, 'pos': 0.103, 'compound': -0.9999}\n",
      "Chapter 8 {'neg': 0.12, 'neu': 0.786, 'pos': 0.094, 'compound': -0.9998}\n",
      "Chapter 9 {'neg': 0.097, 'neu': 0.824, 'pos': 0.079, 'compound': -0.9996}\n",
      "Chapter 10 {'neg': 0.086, 'neu': 0.733, 'pos': 0.181, 'compound': 1.0}\n"
     ]
    }
   ],
   "source": [
    "for nr, chapter in enumerate(chapters):\n",
    "    scores = analyzer.polarity_scores(chapter)\n",
    "    print(\"Chapter\", nr + 1, scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
